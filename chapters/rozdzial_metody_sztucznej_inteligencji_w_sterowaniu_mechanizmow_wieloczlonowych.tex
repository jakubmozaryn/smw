
%Rodzia³ 8
\newpage
\chapter{Metody sztucznej inteligencji w sterowaniu mechanizmów wielocz³onowych - Janek+Kuba}
%
\section{Sieci neuronowe do modelowania mechanizmów wielocz³onowych}
%
  Sztuczne sieci neuronowe s¹ jedn¹ z popularnych metod stosowanych do aproksymacji funkcji nieliniowych. Inspiracj¹ do ich opracowania by³y badania struktur biologicznych oraz sztucznej inteligencji. Budowa oraz sposób dzia³ania sztucznych sieci neuronowych pozwoli³y na wykorzystanie ich w wielu dziedzinach niezwi¹zanych bezpoœrednio z biologi¹ m.in. w naukach technicznych, fizyce i ekonomii.
%
\subsection{Model neuronu}
%
  Podstawowym elementem sieci neuronowej jest pojedyncza struktura nazywana \textbf{neuronem}, który sk³ada siê z elementu sumuj¹cego wagowo sygna³y wejœciowe, tzw. sumatora, oraz elementu przetwarzaj¹cego sygna³ wyjœciowy sumatora. Ogólny model matematyczny neuronu opiera siê na klasycznym modelu \emph{McCullocha - Pittsa} \cite{mcculloch:logical}.
  %
  \par Model matematyczny pojedynczego neuronu jest opisany nastêpuj¹c¹ zale¿noœci¹
  %
  \begin{equation}\label{4.2.1}
  \displaystyle
  \begin{array}{l}
  x=b+\displaystyle\sum_{i=1}^{n} w_{i}u_{i}
  \\y=f(x)
  \end{array}
  \end{equation}
  %
  gdzie $x$ - sygna³ wyjœciowy sumatora, $u_{i}$ - $i$-ty sygna³ wejœciowy neuronu, $b$ - przesuniêcie sygna³u $x$, $n$ - liczba sygna³ów wejœciowych neuronu, $w_{i}$ - waga $i$-tego sygna³u wejœciowego neuronu, $y$ - sygna³ wyjœciowy neuronu, $f(x)$ - funkcja aktywacji neuronu.
  %
  \par Na rys. \ref{rys4.1} przedstawiono strukturê modelu neuronu (\ref{4.2.1})
  %
  \begin{figure}[htb!]
  	\begin{center}
  		\includegraphics[scale=1]{figures/fig8_1}
  		\caption{Struktura modelu neuronu}\label{rys4.1}
  	\end{center}
  \end{figure}
  %
  \par Funkcj¹ aktywacji pojedynczego neuronu mo¿e byæ funkcja liniowa - neuron liniowy, lub nieliniowa - neuron nieliniowy. W wiêkszoœci zastosowañ
  przyjmuje siê, ¿e jest to funkcja ci¹g³a i ró¿niczkowalna. W praktyce najczêœciej wykorzystywane s¹ nastêpuj¹ce funkcje aktywacji:
  %
  \begin{itemize}
  	\item { \textbf{liniowa funkcja aktywacji (neuron liniowy)}
  		%
  		\begin{equation}\label{4.2.3}
  		f(x)=a_{\mathrm{ln}}x
  		\end{equation}
  		%
  		gdzie $a_{\mathrm{ln}}$ - wspó³czynnik nachylenia funkcji.
  		%
  		\par Funkcja liniowa przyjmuje wartoœci w przedziale $( -\infty$ , $+ \infty )$ (rys. \ref{rys4.2}.a),
  		a jej pochodna wzglêdem $x$ ma postaæ
  		%
  		\begin{equation}\label{4.2.4}
  		f'_{x}(x)=\frac{\partial{f(x)}}{\partial{x}}=a_{\mathrm{ln}}
  		\end{equation}
  		%
  	}
  	\item
  	{\textbf{sigmoidalna funkcja aktywacji (neuron nieliniowy)}
  		%
  		\par Funkcja sigmoidalna mo¿e mieæ postaæ unipolarn¹
  		%
  		\begin{equation}\label{4.2.5}
  		f(x)=\frac{1}{1+e^{-a_{\mathrm{su}}x}}
  		\end{equation}
  		%
  		gdzie $a_{\mathrm{su}}$ - parametr funkcji sigmoidalnej unipolarnej.
  		%
  		\par Funkcja sigmoidalna unipolarna przyjmuje wartoœci w przedziale (0,1) (rys. \ref{rys4.2}.b), a jej pochodna wzglêdem $x$ ma postaæ
  		%
  		\begin{equation}\label{4.2.6}
  		f'_{x}(x)=\frac{\partial{f(x)}}{\partial{x}}=a_{\mathrm{su}}f(x)(1-f(x))
  		\end{equation}
  		%
  		\par Funkcja sigmoidalna mo¿e mieæ równie¿ postaæ bipolarn¹
  		%
  		\begin{equation}\label{4.2.7}
  		f(x)=tanh(a_{\mathrm{sb}}x)=\frac{e^{a_{\mathrm{sb}}x}-e^{-a_{\mathrm{sb}}x}}{e^{a_{\mathrm{sb}}x}+e^{-a_{\mathrm{sb}}x}}
  		\end{equation}
  		%
  		gdzie $a_{\mathrm{sb}}$ - parametr funkcji sigmoidalnej bipolarnej.
  		%
  		\par Funkcja sigmoidalna bipolarna
  		przyjmuje wartoœci w przedziale (-1,1) (rys. \ref{rys4.2}.c), a jej pochodna wzglêdem $x$ ma postaæ
  		%
  		\begin{equation}\label{4.2.8}
  		f'_{x}(x)=\frac{\partial{f(x)}}{\partial{x}}=tanh'(a_{\mathrm{sb}}x)=a_{\mathrm{sb}}(1-f^{2}(x))
  		\end{equation}
  		%
  	}
  \end{itemize}
  %8
  Na rys. \ref{rys4.2} przedstawiono wykresy funkcji aktywacji (\ref{4.2.3}), (\ref{4.2.5}), (\ref{4.2.7}).
  %
  \begin{figure}[htb!]
  	\begin{center}
  		\includegraphics[scale=0.9]{figures/fig8_2}
  		\caption{Wykresy funkcji aktywacji neuronu: a) funkcja
  			liniowa (\ref{4.2.3}), b) funkcja sigmoidalna unipolarna (\ref{4.2.5}), c) funkcja sigmoidalna bipolarna (\ref{4.2.7})}\label{rys4.2}
  	\end{center}
  \end{figure}
  %
  \subsection{Modele sztucznych sieci neuronowych}
  %
  \subsection{Sieæ jednowarstwowa jednokierunkowa}
  %
  Sieæ jednowarstwowa jednokierunkowa (tzw. perceptron jednowarstwowy) posiada $n$ sygna³ów wejœciowych $u=[u_{i}]_{n \times 1}$ oraz $m$ neuronów, które nie s¹ ze sob¹ po³¹czone. Z ka¿dym neuronem zwi¹zane s¹: wagi $w_{j,i}$ sygna³ów wejœciowych, sygna³ wyjœciowy sumatora $x_{j}$, przesuniêcie $b_{j}$
  sygna³u $x_{j}$, funkcja aktywacji $f_{j}(x_{j})$, oraz sygna³ wyjœciowy $y_{j}$. Tak wiêc perceptron jednowarstwowy posiada $m$ sygna³ów wyjœciowych $y=[y_{j}]_{m \times 1}$.
  %
  \par Przetwarzanie danych zachodz¹ce w perceptronie jednowarstwowym opisane jest nastêpuj¹co
  %
  \begin{equation}\label{4.3.5}
  \begin{array}{l}
  x=b+Wu \\
  y=f(x)
  \end{array}
  \end{equation}
  %
  gdzie $u=[u_{i}]_{n \times 1}$ - wektor sygna³ów wejœciowych sieci, $x=[x_{j}]_{m \times 1}$ - wektor sygna³ów wyjœciowych sumatorów zwi¹zanych z poszczególnymi neuronami, $b=[b_{j}]_{m \times 1}$ - wektor przesuniêæ sygna³ów wyjœciowych sumatorów zwi¹zanych z poszczególnymi neuronami, $W=[w_{j,i}]_{m \times n}$ - macierz wag sygna³ów wejœciowych sieci, $y=[y_{j}]_{m \times 1}$ - wektor sygna³ów wyjœciowych sieci, $f(x)=[f_{j}(x_{j})]_{m \times 1}$ - wektor funkcji aktywacji neuronów.
  %
  \par Na rys. \ref{rys4.5} przedstawiono strukturê jednowarstwowej jednokierunkowej sieci neuronowej.
  %
  \begin{figure}[htb!]
  	\begin{center}
  		\includegraphics[scale=1]{figures/fig8_3}
  		\caption{Struktura jednowarstwowej jednokierunkowej sieci neuronowej}\label{rys4.5}
  	\end{center}
  \end{figure}
  %
  \subsection{Sieæ wielowarstwowa jednokierunkowa}
  %
  Najczêœciej wykorzystywanym modelem sztucznej sieci neuronowej jest sieæ wielowarstwowa jednokierunkowa (ang. \emph{feedforward neural network}), która ma $n$ sygna³ów wejœciowych i $m$ sygna³ów wyjœciowych. Sieæ jednokierunkowa wielowarstwowa nazywana jest tak¿e perceptronem wielowarstwowym - MLP (ang. \emph{multi layer perceptron}) i sk³ada siê z szeregowo po³¹czonych warstw neuronów. Ka¿da z warstw ma strukturê perceptronu jednowarstwowego
  (rys. \ref{rys4.5}). Warstwa nazywana \textbf{warstw¹ wyjœciow¹} wyznacza sygna³y wyjœciowe z sieci neuronowej. Warstwy, których sygna³y wyjœciowe nie s¹ sygna³ami wyjœciowymi sieci nazywane s¹ \textbf{warstwami ukrytymi}. Przep³yw sygna³ów we wszystkich warstwach jest jednokierunkowy, od wejœcia do wyjœcia. W sieci wielowarstwowej jednokierunkowej istnieje przynajmniej jedna warstwa ukryta.
  %
  \par W przypadku sieci neuronowej $L$ warstwowej, ka¿da warstwa posiada $n^{(i)}$ sygna³ów wejœciowych oraz $m^{(i)}$ neuronów i $m^{(i)}$ sygna³ów wyjœciowych, gdzie $i$ oznacza numer warstwy. W przypadku najczêœciej stosowanej sieci zupe³nej ka¿dy sygna³ wejœciowy do warstwy po³¹czony jest z ka¿dym neuronem wagowo, a ka¿dy z sygna³ów wyjœciowych z poprzedniej warstwy jest sygna³em wejœciowym do kolejnej warstwy
  %
  \begin{equation}\label{4.3.2}
  \begin{array}{l}
  u^{(1)}=[u^{(1)}_{j}]_{n^{(1)} \times 1}=u, \ y^{(1)}=[y^{(1)}_{j}]_{m^{(1)} \times 1}, \ n^{(1)}=n\\
  u^{(i)}=[u^{(i)}_{j}]_{n^{(i)} \times 1}=y^{(i-1)}, \ y^{(i)}=[y^{(i)}_{j}]_{m^{(i)} \times 1}, \ n^{(i)}=m^{(i-1)}, \ i=2,\dots,L \\
  \end{array}
  \end{equation}
  %
  gdzie $u^{(1)}$ - wektor sygna³ów wejœciowych do sieci, $u^{(i)}$ - wektor sygna³ów wejœciowych do warstwy $i$, $y^{(i)}$ - wektor sygna³ów wyjœciowych z warstwy $i$.
  %
  \par Sygna³ami wyjœciowymi z sieci neuronowej s¹ sygna³y wyjœciowe z ostatniej warstwy
  %
  \begin{equation}\label{4.3.3}
  y_{\mathrm{NN}}=[y_{\mathrm{NN}i}]_{m^{(L)} \times 1}=y^{(L)},\ \mathrm{gdzie} \ m^{(L)}=m
  \end{equation}
  %
  Model wielowarstwowej jednokierunkowej sztucznej sieci neuronowej, sk³adaj¹cej siê z po³¹czonych szeregowo $L$ sieci jednowarstwowych jednokierunkowych, zosta³ przedstawiony na rys. \ref{rys4.3}.
  %
  \begin{figure}[htb!]
  	\begin{center}
  		\includegraphics[scale=1]{figures/fig8_4}
  		\caption{Struktura wielowarstwowej jednokierunkowej sieci neuronowej}\label{rys4.3}
  	\end{center}
  \end{figure}
  %
  \par Przetwarzanie danych zachodz¹ce w warstwie $i$ sieci neuronowej wielowarstwowej jednokierunkowej zgodnie z przyjêtymi funkcjami aktywacji, opisane jest nastêpuj¹co
  %
  \begin{equation}\label{4.3.4}
  \begin{array}{l}
  x^{(i)}=b^{(i)}+W^{(i)}u^{(i)} \\
  y^{(i)}=f^{(i)}(x^{(i)})
  \end{array}, \ i=1,\ldots,L
  \end{equation}
  %
  gdzie $u^{(i)}=[u^{(i)}_{j}]_{n^{(i)} \times 1}$ - wektor sygna³ów wejœciowych do warstwy, $x^{(i)}=[x^{(i)}_{j}]_{m^{(i)} \times 1}$ - wektor sygna³ów wyjœciowych sumatorów zwi¹zanych z poszczególnymi neuronami warstwy, $y^{(i)}=[y^{(i)}_{j}]_{m^{(i)} \times 1}$ - wektor sygna³ów wyjœciowych z warstwy, $W^{(i)}=[w^{(i)}_{j,k}]_{m^{(i)}\times n^{(i)}}$ - macierz wag warstwy, $b^{(i)}=[b^{(i)}_{j}]_{m^{(i)}\times 1}$ - wektor przesuniêæ sygna³ów wyjœciowych sumatorów zwi¹zanych z poszczególnymi neuronami warstwy, $f^{(i)}(x^{(i)})=[f^{(i)}_{k}(x^{(i)}_{k})]_{m^{(i)} \times 1}$ - wektor funkcji aktywacji neuronów warstwy.
  %
  \par Struktura $i$-tej warstwy sieci neuronowej, opisana równaniami (\ref{4.3.4}), zosta³a przedstawiona na rys. \ref{rys4.4}. Jest ona analogiczna do struktury przedstawionej na rys. (\ref{rys4.5}).
  %
  \par Wykorzystuj¹c przedstawiony model sztucznej sieci neuronowej mo¿na zaprojektowaæ sieæ neuronow¹ realizuj¹c¹ nastêpuj¹ce przekszta³cenie
  %
  \begin{equation}\label{4.4.3}
  y_{\mathrm{NN}}=F_{\mathrm{NN}}(u), \qquad F_{\mathrm{NN}}:R^{n}\rightarrow R^{m}, \qquad y_{\mathrm{NN}}\in R^{m},u\in R^{n}
  \end{equation}
  %
  gdzie $y_{\mathrm{NN}}$ - wektor sygna³ów wyjœciowych (\ref{4.3.3}) sieci neuronowej, $u$ - wektor sygna³ów wejœciowych sieci neuronowej.
  %
  \begin{figure}[htb!]
  	\begin{center}
  		\includegraphics[scale=1]{figures/fig8_5}
  		\caption{Struktura $i$-tej warstwy sztucznej sieci neuronowej}\label{rys4.4}
  	\end{center}
  \end{figure}
  %
  \subsection{Aproksymacja funkcji za pomoc¹ sieci neuronowej}
  %
  Sieæ neuronowa mo¿e byæ wykorzystana do aproksymacji nieznanej funkcji wielowymiarowej postaci
  %
  \begin{equation}\label{4.4.1}
  y=F(u),\qquad F:R^{n}\rightarrow R^{m}, \qquad y\in R^{m},u\in R^{n}
  \end{equation}
  %
  gdzie $u$ - wektor argumentów funkcji $F(u)$, $y$ - wektor wartoœci funkcji $F(u)$.
  %
  \par Aproksymacj¹ w przypadku sieci neuronowej bêdziemy nazywali funkcjê $y_{\mathrm{NN}}=F_{\mathrm{NN}}(u)$ realizowan¹ przez sieæ neuronow¹ (\ref{4.4.3}), przybli¿aj¹c¹ nieznan¹ funkcjê (\ref{4.4.1}).
  %
  \par Przyjmijmy, ¿e istnieje zbiór $N$ próbek $s(k)$ wartoœci funkcji (\ref{4.4.1}) w postaci par uporz¹dkowanych
  %
  \begin{equation}\label{4.4.2}
  s(k)=\{ u(k), y(k) : y(k)=F[u(k)]\},\qquad k=1,\ldots,N
  \end{equation}
  %
  gdzie $k$ - numer próbki.
  %
  \par Je¿eli dla ka¿dej próbki ze zbioru (\ref{4.4.2}) zostanie spe³niony warunek
  %
  \begin{equation}\label{4.4.4}
  |y_{\mathrm{NN}}(k)-y(k)|<\varepsilon,
  \end{equation}
  %
  to mo¿na przyj¹æ, ¿e sieæ aproksymuje funkcjê (\ref{4.4.1}) z dok³adnoœci¹ $\varepsilon=[\varepsilon_{i}]_{m \times 1}$.
  %
  \par Zadanie aproksymacji funkcji (\ref{4.4.1}) za pomoc¹ sieci neuronowej mo¿na przedstawiæ nastêpuj¹co. Przyjmuje siê funkcjê celu
  %
  \begin{equation}\label{4.5.1}
  E=f[e(1),\ldots,e(N)]
  \end{equation}
  %
  gdzie $e(k)$ - wektor b³êdu aproksymacji dla $k$-tej próbki ma postaæ
  %
  \begin{equation}\label{4.4.5}
  e(k)=[e_{i}(k)]_{m \times 1}=y_{\mathrm{NN}}(k)-y(k)
  \end{equation}
  %
  Na ogó³, podczas trenowania sieci neuronowej, minimalizowana jest funkcji celu (\ref{4.5.1}), któr¹ mo¿na zapisaæ jako funkcjê wektora wszystkich wag sieci
  %
  \begin{equation}\label{4.5.14}
  E=E(W)
  \end{equation}
  %
  gdzie
  %
  \begin{equation}\label{4.5.15}
  W=[b_{1}^{(1)},w_{1,1}^{(1)},\ldots,w_{m^{(1)},n^{(1)}}^{(1)},b_{1}^{(2)},\ldots,w_{m^{(L)},n^{(L)}}^{(L)}]^{T} =[w_{i}]_{n_{\mathrm{W}}\times 1}=[w_{1},\ldots,w_{n_{\mathrm{W}}}]^{T}
  \end{equation}
  %
  oraz $n_{\mathrm{W}}$ - liczba wszystkich wag i przesuniêæ sieci neuronowej, która dla $L$ warstwowej jednokierunkowej sieci zupe³nej wynosi
  %
  \begin{equation}
  n_{\mathrm{W}}=\sum_{l=1}^{L}m^{(l)}(n^{(l)}+1)
  \end{equation}
  %
  Podczas trenowania nale¿y tak dobraæ wartoœci wag sieci neuronowej $W$, ¿eby funkcja celu (\ref{4.5.1}) osi¹ga³a minimum.
  %
  \par Jeœli funkcja celu osi¹ga zbyt du¿e wartoœci, to mo¿na zaprojektowaæ inn¹ sieæ np. o zmienionej liczbie neuronów
  lub warstw i podj¹æ próbê aproksymacji funkcji (\ref{4.4.1}) za pomoc¹ nowej sieci.
  %
  \par Czêsto formu³uje siê zadanie aproksymacji, w tym dobór struktury sieci i wag tak, ¿e wymaga siê, aby funkcja celu osi¹ga³a wartoœæ mniejsz¹ ni¿ pewna przyjêta wartoœæ zadana $E_{\mathrm{0}}$.
  %
  \par Jako funkcja celu czêsto wykorzystywana jest œrednia suma kwadratów b³êdów pomiêdzy wyjœciem z sieci, a wartoœci¹ aproksymowanej funkcji po $N$ próbkach, tzw. œredni b³¹d kwadratowy - MSE (ang. \emph{mean squared error,})
  %
  \begin{equation}\label{4.5.2}
  E_{\mathrm{MSE}}=\frac{1}{N}\sum_{k=1}^{N}\sum_{i=1}^{m}e_{i}(k)^2
  \end{equation}
  %
  Inne funkcje celu wykorzystywane podczas aproksymacji to np. œredni b³¹d bezwzglêdny - MAE (ang. \emph{mean absolute error}), pierwiastek œredniego b³êdu kwadratowego - RMSE (ang. \emph{root mean squared error}), œredni b³¹d kwadratowy z regularyzacj¹ - MSEREG (ang. \emph{mean squared error
  	with regularization}) \cite{masters:sieci,osowski:siecialg,jankowski:ontogeniczne,matlab:neural}.
  %
  \par Zalet¹ sieci neuronowej jest mo¿liwoœæ realizacji sieci aproksymuj¹cej z zadan¹ dok³adnoœci¹ prawie ka¿d¹ funkcjê ci¹g³¹ okreœlon¹ na zbiorze zwartym \cite{hornik:networkuniversal,cybenko:approximation,kurkova:kolmogorov}. Nale¿y jednak zwróciæ uwagê, ¿e dok³adnoœæ aproksymacji za pomoc¹ sieci neuronowej zale¿y od liczby neuronów, rodzaju funkcji aktywacji neuronów w warstwach ukrytych, liczby próbek ucz¹cych, algorytmu doboru wag oraz architektury sieci. Ka¿de z tych zagadnieñ wymaga rozwa¿enia podczas projektowania sztucznej sieci neuronowej dla konkretnego zastosowania.
  %
  \section{Trenowanie sztucznej sieci neuronowej}
  %
  Parametrami sieci neuronowej jest zbiór wag $W$ (\ref{4.5.15}), który nale¿y wyznaczyæ tak, aby funkcja (\ref{4.4.3}) realizowana przez sieæ jak najlepiej aproksymowa³a nieznan¹ funkcjê (\ref{4.4.1}). Proces doboru wag $W$ nazywany jest \textbf{procesem uczenia} lub \textbf{procesem trenowania} sieci neuronowej.
  %
  \par Proces doboru neuronów i liczby warstw bêdziemy nazywali \textbf{procesem projektowania} sieci neuronowej.
  %
  \subsection{Adaptacja wag sieci neuronowej}
  %
  Do minimalizacji funkcji celu (\ref{4.5.14}) mo¿na wykorzystaæ iteracyjne algorytmy rozwi¹zywania zadania programowania
  nieliniowego bez ograniczeñ \cite{findeisen:optymalizacja}. W przypadku sieci neuronowej jednokierunkowej wielowarstwowej zadanie to polega na znalezieniu wektora wag $\hat{W}$ spe³niaj¹cego zale¿noœæ
  %
  \begin{equation}\label{4.5.16}
  E(\hat{W})=\min_{W}E(W)
  \end{equation}
  %
  W iteracyjnych algorytmach, w ka¿dej iteracji, wartoœci wag s¹ modyfikowane wg zale¿noœci
  %
  \begin{equation}\label{4.5.17}
  W_{(i+1)}=W_{(i)}+\eta_{(i)}p_{(i)}
  \end{equation}
  %
  gdzie $W_{(i)}$ - macierz wag w $i$-tej iteracji, $p_{(i)} \in R^{n_{\mathrm{W}}}$ - kierunek poprawy, $\eta_{(i)} \in R$ - wspó³czynnik kroku.
  %
  \par Kierunek poprawy oraz wspó³czynnik kroku s¹ wyznaczane tak, aby
  %
  \begin{equation}\label{4.5.21}
  E(W_{(i)}+\eta_{(i)}p_{(i)})<E(W_{(i)})
  \end{equation}
  %
  Minimum funkcji celu charakteryzuje siê zerow¹ wartoœci¹ gradientu funkcji celu.
  %
  \par W celu okreœlenia w kolejnych iteracjach kierunku minimalizacji funkcji celu oraz wspó³czynnika kroku, w procesie trenowania sieci neuronowej, wykorzystuje siê tzw. \emph{metody kierunków poprawy} np. metodê najwiêkszego spadku, gradientów sprzê¿onych, \emph{Levenberga - Marquardta} \cite{masters:sieci,osowski:siecialg,matlab:neural,findeisen:optymalizacja}.
  %
  \par Poniewa¿ liczba iteracji mo¿e byæ bardzo du¿a, w stosowanych algorytmach wyznaczania wag sieci neuronowej okreœla siê warunki zatrzymania dzia³ania algorytmu - tzw. warunki stopu. Zwykle podstawowymi wielkoœciami branymi pod uwagê jest za³o¿ona minimalna wartoœæ funkcji celu $E_{\mathrm{0}}$ oraz za³o¿ona maksymalna liczba iteracji treningowych $i_{\mathrm{max}}$.
  %
  \par Ogóln¹ postaæ gradientowego algorytmu trenowania sieci neuronowej mo¿na przedstawiæ nastêpuj¹co:
  %
  \par \textbf{Algorytm 4.1. Gradientowy algorytm trenowania sieci neuronowej}
  \begin{enumerate}
  	\item {\emph{Przyj¹æ ¿¹dan¹ wartoœæ funkcji celu sieci neuronowej $E_{\mathrm{0}}$,\\
  			przyj¹æ maksymaln¹ liczbê iteracji treningowych $i_{\mathrm{max}}$,\\
  			przyj¹æ wartoœæ pocz¹tkow¹ optymalizowanego wektora wag $W_{(0)}$,\\
  			przyj¹æ numer iteracji pocz¹tkowej $i=0$.}
  	}
  	\item{
  		\emph{Przyj¹æ $i=i+1$}
  	}
  	\item{
  		\emph{Sprawdziæ warunek}
  		%
  		\begin{equation}\label{4.5.22}
  		i \geq i_{\mathrm{max}}
  		\end{equation}
  		%
  		\emph{Jeœli warunek (\ref{4.5.22}) jest spe³niony zakoñczyæ trenowanie sieci.}
  	}
  	\item {
  		\emph{Obliczyæ wartoœæ funkcji celu sieci neuronowej $E(W_{(i)})$ a nastêpnie sprawdziæ warunek:}
  		%
  		\begin{equation}\label{4.5.23a}
  		E(W_{(i)})\leq E_{\mathrm{0}}
  		\end{equation}
  		%
  		\emph{Je¿eli warunek (\ref{4.5.23a}) jest spe³niony zakoñczyæ trenowanie sieci.}
  		%
  	}
  	\item {\emph{Wyznaczyæ kierunek poprawy $p_{(i)}$ zgodnie z wybran¹ metod¹ optymalizacyjn¹.}}
  	\item {\emph{Wyznaczyæ wartoœæ wspó³czynnika kroku $\eta_{(i)}$ zgodnie z wybran¹ metod¹ optymalizacyjn¹.}}
  	\item {
  		\emph{Okreœliæ wartoœci elementów wektora wag $W_{(i+1)}$ wg zale¿noœci}
  		%
  		\begin{equation}\label{4.5.25}
  		W_{(i+1)}=W_{(i)}+\eta_{(i)}p_{(i)}
  		\end{equation}
  		%
  	}
  	\item{
  		\emph{Wróciæ do punktu 2.}
  	}
  \end{enumerate}
  %
  \begin{flushright}
  	\framebox[6pt][c]{}
  \end{flushright}
  %
  Zaawansowane optymalizacyjne algorytmy gradientowe wykorzystuj¹ rozwiniêcie funkcji celu (\ref{4.5.14}) sieci neuronowej w szereg \emph{Taylora} w punkcie $W_{(i)}$, ze szczególnym uwzglêdnieniem trzech pierwszych wyrazów
  %
  \begin{equation}\label{4.5.26}
  \begin{array}{ll}
  E(W) & =E(W_{(i)})+[\frac{\partial E}{\partial W}|_{W=W(i)}]^{T}(W-W_{(i)})+\frac{1}{2}(W-W_{(i)})^{T}[\frac{\partial^2 E}{\partial W^2}|_{W=W(i)}](W-W_{(i)})+R(W_{(i)})\\
  & =E(W_{(i)})+\nabla E(W_{(i)})^{T}(W-W_{(i)})+\frac{1}{2}(W-W_{(i)})^{T}H(W_{(i)})(W-W_{(i)})+R(W_{(i)})
  \end{array}
  \end{equation}
  %
  gdzie $R(W_{(i)})$ - reszta rozwiniêcia funkcji celu (\ref{4.5.14}) w szereg \emph{Taylora}, $\nabla E(W_{(i)})$ - wektor gradientu funkcji celu (\ref{4.5.14}) postaci
  %
  \begin{equation}\label{4.5.20}
  \nabla E(W)=\left. \frac{\partial E}{\partial W} \right|_{W=W(i)}=  
  \left. \left[\begin{array}{c}
  \frac{\partial E(W)}{\partial w_{1}}\\
  \vdots\\
  \frac{\partial E(W)}{\partial w_{n_{\mathrm{W}}}}
  \end{array}\right]_{n_{\mathrm{W}}\times n_{\mathrm{W}}} \right|_{W=W(i)}
\end{equation}
  %
  oraz $H(W_{(i)})$ - \emph{hesjan}, macierz drugich pochodnych funkcji celu (\ref{4.5.14}) wzglêdem wag sieci
  %
  \begin{equation}\label{4.5.27}
  H(W_{(i)})=\left. \frac{\partial^2 E}{\partial^2 W} \right|_{W=W(i)}=
  \left. \left[\begin{array}{ccc}
  \frac{\partial^{2}E(W)}{\partial{w_{1}}\partial{w_{1}}} & \ldots & \frac{\partial^{2}E(W)}{\partial{w_{1}}\partial{w_{n_{\mathrm{W}}}}}\\
  \vdots & & \vdots\\
  \frac{\partial^{2}E(W)}{\partial{w_{n_{\mathrm{W}}}}\partial{w_{1}}} & \ldots & \frac{\partial^{2}E(W)}{\partial{w_{n_{\mathrm{W}}}}\partial{w_{n_{\mathrm{W}}}}}\\
  \end{array} \right]_{n_{\mathrm{W}}\times n_{\mathrm{W}}} \right|_{W=W(i)}
  \end{equation}
  %
  W przypadku funkcji celu MSE (\ref{4.5.2}) hesjan (\ref{4.5.27}) jest symetryczny.
  %
  \subsubsection{Metoda wstecznej propagacji b³êdu}
  %
  Gradientowe metody optymalizacji stosowane do doboru wag $W$ sieci neuronowej w procesie trenowania wymagaj¹ znajomoœci wartoœci gradientu funkcji celu wzglêdem ka¿dej z wag sieci (\ref{4.5.20}). Do jego wyznaczenia w sieci wielowarstwowej wykorzystywany jest algorytm
  \textbf{wstecznej propagacji b³êdu} (ang. \emph{error backpropagation}) \cite{rumelhart:learning}. W algorytmie wstecznej propagacji b³êdu wartoœci szukanych elementów wektora gradientu $\nabla E(W)$ (\ref{4.5.20}) obliczane s¹ w kierunku od warstwy wyjœciowej do warstwy wejœciowej sieci neuronowej.
  %
  \par W metodzie wstecznej propagacji b³êdu wymaga siê, aby funkcja aktywacji ka¿dego neuronu by³a ró¿niczkowalna i znana by³a wartoœæ jej pochodnej wzglêdem argumentu. Algorytm wstecznej propagacji b³êdów mo¿na zapisaæ nastêpuj¹co \cite{masters:sieci,osowski:siecialg}.
  %
  \par \textbf{Algorytm 4.2. Wyznaczanie wektora gradientu funkcji celu wielowarstwowej \\jednokierunkowej sieci neuronowej metod¹ wstecznej propagacji b³êdu}
  %
  \begin{enumerate}
  %
  	\item {\emph{Dana jest próbka $s=\{ u, y \}$, liczba sygna³ów wejœciowych do sieci neuronowej $n^{(1)}=n$,liczba warstw sieci $L$, liczba neuronów w warstwach sieci $m^{(i)}, i=1,\ldots,L$, sygna³y wejœciowe do sieci		$u^{(1)}_{j}=u_{j}, j=1,\ldots,n$, macierze wag i wektory przesuniêæ sygna³ów wyjœciowych sumatorów warstw sieci $W^{(i)}, b^{(i)}, i=1,\dots,L$, liczba sygna³ów wyjœciowych z sieci $m^{(L)}=m$, sygna³y wyjœciowe z sieci $y_{\mathrm{NN}}=[y_{\mathrm{NN}i}]_{m^{(L)}\times 1}$}}
  	%
  	\item {\emph{Obliczyæ $x^{(l)}, y^{(l)}$ wg (\ref{4.3.4}) dla $l=1,\ldots, L$.}}
  	%
  	\item {\emph{Przyj¹æ l=L.}}
  	%
  	\item {\emph{Obliczyæ wartoœæ pochodnej funkcji celu sieci neuronowej wzglêdem sygna³ów wyjœciowych z sieci}
  	  			%
  	\begin{equation}\label{4.5.10}
  	E'_{y_{\mathrm{NN}i}}=\frac{\partial{E}}{\partial{y_{\mathrm{NN}i}}},\qquad i=1, \ldots, m^{(L)}
  	\end{equation}
  	%
 	}
    \item {\emph{Wyznaczyæ wartoœæ pochodnej funkcji celu sieci neuronowej wzglêdem sygna³ów $x^{(l)}_{i}$}
   	\\
    	Jeœli $l=L$
   	%
	\begin{equation}\label{4.5.11}
	E'_{x^{(L)}_{i}}=\frac{\partial{E}}{\partial{x^{(L)}_{i}}}=\frac{\partial{f}^{(L)}_{i}(x^{(L)}_{i})}{\partial{x^{(L)}_{i}}}E'_{y_{\mathrm{NN}i}},
	\qquad i=1, \ldots ,m^{(L)},
	\end{equation}    
	%
	jeœli $l<L$ wyznaczyæ
	%
	\begin{equation}\label{4.5.12}
	E'_{x^{(l)}_{i}}=\frac{\partial{E}}{\partial{x^{(l)}_{i}}}=\frac{\partial{f}^{(l)}_{i}(x^{(l)}_{i})}{\partial{x^{(l)}_{i}}}\sum_{j=1}^{m^{(l+1)}}[{w^{(l+1)}_{j,i}}E'_{x^{(l+1)}_{j}}],\qquad i=1,\ldots,m^{(l)}
	\end{equation}
	%
  	}
  	%
  	\item{\emph{Wyznaczyæ pochodne funkcji celu sieci neuronowej wzglêdem wag i przesuniêæ sygna³ów wyjœciowych sumatorów warstwy $l$ sieci, bêd¹ce szukanymi elementami wektora gradientu $\nabla E(W)$ (\ref{4.5.20})}
  				%
  				\begin{equation}\label{4.5.13}
  				E'_{w^{(l)}_{j,i}}=\frac{\partial{E}}{\partial{w^{(l)}_{j,i}}}=u^{(l)}_{i}E'_{x^{(l)}_{j}},\qquad i=1, \ldots, n^{(l)}, j=1, \ldots, m^{(l)}
  				\end{equation}
  				\begin{equation}\label{4.5.13a}
  				E'_{b^{(l)}_{j}}=\frac{\partial{E}}{\partial{b^{(l)}_{j}}}=E'_{x^{(l)}_{j}}, \qquad j=1, \ldots, m^{(l)}
  				\end{equation}
  				%
  	}
  		%
  	\item{\emph{Przyj¹æ $l=l-1$, jeœli $l>0$ przejœæ do punktu 4, w przeciwnym przypadku zakoñczyæ algorytm.}}
  	%
  	\end{enumerate}
  		%
  		\begin{flushright}
  			\framebox[6pt][c]{}
  		\end{flushright}
  		%
  		Odpowiedni wybór funkcji celu sieci neuronowej powinien pozwalaæ na ³atwe wyznaczenie gradientu (\ref{4.5.10}) tej funkcji wzglêdem ka¿dego z sygna³ów wyjœciowych sieci. W aplikacjach sieci neuronowych czêsto jest stosowana funkcja celu $E_{\mathrm{MSE}}$ (\ref{4.5.2}), dla której
  		%
  		\begin{equation}\label{4.5.4}
  		E'_{y_{\mathrm{NN}}}=\left[E'_{y_{\mathrm{NN}i}}\right]_{m^{(L)} \times 1}=E'_{(\mathrm{MSE})y_{\mathrm{NN}}}=\left[\sum_{k=1}^{N}\frac{\partial E_{\mathrm{MSE}}}{\partial y_{\mathrm{NN}i}(k)}\right]_{m^{(L)} \times 1}=\left[\frac{2}{N}\sum_{k=1}^{N}e_{i}(k)\right]_{m^{(L)} \times 1}
  		\end{equation}
  		%
  		\subsubsection{Metoda najwiêkszego spadku}
  		%
  		W metodzie najwiêkszego spadku przyjmowany jest kierunek poprawy $p_{(i)}$ postaci
  		%
  		\begin{equation}\label{4.5.28}
  		p_{(i)}=-\nabla E(W_{(i)}),
  		\end{equation}
  		%
  		natomiast wartoœæ wspó³czynnika kroku powinna spe³niaæ zale¿noœæ
  		%
  		\begin{equation}\label{4.5.29}
  		\eta_{(i)}>0
  		\end{equation}
  		%
  		W najprostszym przypadku metody najwiêkszego spadku przyjmowana jest odpowiednio ma³a sta³a wartoœæ $\eta_{(i)}$, jednak mo¿e to spowodowaæ, ¿e funkcja celu sieci neuronowej bêdzie wolno zbiega³a do optymalnego rozwi¹zania. W celu poprawy zbie¿noœci i szybszego znalezienia rozwi¹zania bliskiego optymalnemu, do wyznaczenia w kolejnych iteracjach wartoœci wspó³czynnika kroku $\eta_{(i)}$, wykorzystuje siê algorytmy minimalizacji funkcji celu wzd³u¿ wyznaczonego kierunku $p_{(i)}$ np. metod¹ z³otego podzia³u, interpolacji kwadratowej, \emph{Charalambousa}, \emph{Brenta } \cite{findeisen:optymalizacja,matlab:neural}. Stosowane s¹ tak¿e inne modyfikacje algorytmu najwiêkszego spadku, do których nale¿¹ m.in. metoda najwiêkszego spadku z momentem \cite{osowski:siecialg,osowski:sieci,matlab:neural}, metoda QUICKPROP (ang. \emph{quick backpropagation}) \cite{fahlman:quickprop}, metoda RPROP (ang. \emph{resilent backpropagation}) \cite{riedmiller:rprop}.
  		%
  		\subsubsection{Metoda gradientów sprzê¿onych}
  		%
  		Metoda gradientów sprzê¿onych, w przypadku nieliniowego uk³adu równañ (np. sieci neuronowej), jest modyfikacj¹ metody gradientów sprzê¿onych dla uk³adu równañ liniowych \cite{shewchuk:introduction94}. Wykorzystuje model kwadratowy funkcji celu sieci neuronowej $E(W)$ w otoczeniu wartoœci $W_{(i)}$, który otrzymuje siê w wyniku obciêcia rozwiniêcia (\ref{4.5.26}) do trzech pierwszych wyrazów.
  		%
  		\par W pierwszej iteracji algorytmu gradientów sprzê¿onych obliczany jest kierunek poprawy
  		%
  		\begin{equation}\label{4.5.30}
  		p_{(0)}=-\nabla E(W_{(0)})
  		\end{equation}
  		%
  		W kolejnych iteracjach okreœlane s¹ wartoœci elementów wektora $W_{(i)}$
  		%
  		\begin{equation}\label{4.5.31}
  		W_{(i)}=W_{(i-1)}+\eta_{(i-1)}p_{(i-1)}
  		\end{equation}
  		%
  		oraz kierunek poprawy w iteracji $i$
  		%
  		\begin{equation}\label{4.5.32}
  		p_{(i)}=-\nabla E(W_{(i)})+\beta_{(i-1)}p_{(i-1)}
  		\end{equation}
  		%
  		gdzie $\beta_{(i-1)}$ - wspó³czynnik obliczany wg odpowiednich formu³, do których nale¿¹ m.in. formu³a \emph{Fletchera-Reevesa} lub formu³a \emph{Polaka-Ribier\`{e}'a} \cite{findeisen:optymalizacja,shewchuk:introduction94}.
  		%
  		\par Do wyznaczenia w kolejnych iteracjach wartoœci wspó³czynnika kroku $\eta_{(i)}$ wykorzystuje siê algorytmy minimalizacji funkcji celu wzd³u¿ wyznaczonego kierunku $p_{(i)}$ np. metoda \emph{Charalambous'a}, metoda \emph{Brendt'a}, metoda z³otego podzia³u \cite{matlab:neural}.
  		%
  		\par Algorytm gradientów sprzê¿onych charakteryzuje siê skoñczon¹ liczb¹ iteracji $n_{\mathrm{iter}}$ \cite{shewchuk:introduction94,nocedal:numopt}, która jest ograniczona przez liczbê modyfikowanych parametrów (wag sieci) $n_{\mathrm{W}}$
  		%
  		\begin{equation}\label{4.5.40}
  		n_{\mathrm{iter}}\leq n_{\mathrm{W}}
  		\end{equation}
  		%
  		\subsubsection{Metoda \emph{Levenberga - Marquardta}}
  		%
  		Metoda \emph{Levenberga - Marquardta} \cite{levenberg:method,marquardt:algorithm,osowski:siecialg,osowski:sieci,matlab:neural} wykorzystuje do modyfikacji 
  		wag sieci neuronowej trzy pierwsze wyrazy i oszacowanie reszty rozwiniêcia (\ref{4.5.26}) funkcji celu. W metodzie \emph{Levenberga - Marquardta} nie jest wyznaczany kierunek poprawy i wspó³czynnik kroku, tak jak ma to miejsce w metodach najwiêkszego spadku, lub gradientów sprzê¿onych. Metoda \emph{Levenberga - Marquardta} jest szczególnym przypadkiem \emph{metody zmiennej metryki} \cite{findeisen:optymalizacja} gdzie zmiany wag $W$ sieci neuronowej w $i$-tej iteracji wyznacza siê wg zale¿noœci
  		%
  		\begin{equation}\label{4.5.34}
  		W_{(i+1)}=W_{(i)}-H(W_{(i)})^{-1}\nabla E(W_{(i)})
  		\end{equation}
  		%
  		Przybli¿enia hesjanu i gradientu funkcji celu wzglêdem wag sieci, stosowane w metodzie \emph{Levenberga - Marquardta}, s¹ nastêpuj¹ce
  		%
  		\begin{equation}\label{4.5.41}
  		H(W_{(i)})\cong [K(W_{(i)})^{T}K(W_{(i)})+R(W_{(i)})]
  		\end{equation}
  		%
  		oraz
  		%
  		\begin{equation}\label{4.5.42}
  		\nabla E(W_{(i)})\cong K(W_{(i)})^{T}e_{(i)}
  		\end{equation}
  		%
  		gdzie $K(W_{(i)})$ - \emph{jakobian}, macierz pochodnych elementów wektora b³êdu $e_{(i)}$ (\ref{4.4.5}) wzglêdem ka¿dej z wag sieci
  		%
  		\begin{equation}\label{4.5.35}
  		K(W_{(i)})=\left. \frac{\partial e}{\partial W}\right|_{W=W(i)}=\left. \left[\begin{array}{cccc}
  		\frac{\partial e_{1}}{\partial w_{1}} & \frac{\partial e_{1}}{\partial w_{2}} & \ldots & \frac{\partial e_{1}}{\partial w_{n_{\mathrm{W}}}}\\
  		\frac{\partial e_{2}}{\partial w_{1}} & \frac{\partial e_{2}}{\partial w_{2}} & \ldots & \frac{\partial e_{2}}{\partial w_{n_{\mathrm{W}}}}\\
  		\ldots & \ldots & \ldots & \ldots\\
  		\frac{\partial e_{m}}{\partial w_{1}} & \frac{\partial e_{m}}{\partial w_{2}} & \ldots & \frac{\partial e_{m}}{\partial w_{n_{\mathrm{W}}}}
  		\end{array}\right]_{n_{\mathrm{W}}\times n_{\mathrm{W}}} \right|_{W=W(i)}
  		\end{equation}
  		%
  		W metodzie \emph{Levenberga - Marquardta} w celu uzyskania dodatnio okreœlonego przybli¿onego hesjanu (\ref{4.5.41}) stosuje siê nastêpuj¹ce
  		przybli¿enie reszty $R(W_{(i)})$ rozwiniêcia (\ref{4.5.26})
  		%
  		\begin{equation}\label{4.5.36}
  		R(W_{(i)})\cong \mu_{(i)}\textbf{I}_{n_{\mathrm{W}} \times n_{\mathrm{W}}}
  		\end{equation}
  		%
  		gdzie $\mu_{(i)}$ - czynnik regularyzacyjny, tzw. \emph{parametr Marquardta}.
  		%
  		\par Tak wiêc, w metodzie \emph{Levenberga - Marquardta}, zmiany wag sieci neuronowej w $i$-tej iteracji treningowej wyznacza siê wg zale¿noœci
  		%
  		\begin{equation}\label{4.5.43}
  		W_{(i+1)}=W_{(i)}-[K(W_{(i)})^{T}K(W_{(i)})+\mu_{(i)}\textbf{I}]^{-1}K(W_{(i)})^{T}e_{(i)}
  		\end{equation}
  		%
  		Minimalizacja funkcji celu polega na zmianach wartoœci czynnika regularyzacyjnego $\mu_{(i)}$ i wag sieci neuronowej podczas kolejnych iteracji w zale¿noœci od wartoœci funkcji celu \cite{osowski:sieci}.
  		%
  		\subsubsection{Sposoby prezentacji próbek i modyfikacji wag podczas trenowania sieci neuronowej}
  		%
  		W przypadku trenowania sieci neuronowej rozró¿nia siê dwie podstawowe metody prezentacji próbek
  		ze zbioru treningowego i modyfikacji wag sieci \cite{principe:neuralandadaptive}.
  		%
  		\par Pierwsza metoda nazywana jest \textbf{trenowaniem przyrostowym}, inkrementalnym (ang. \emph{incremental
  			training}) lub trenowaniem w trybie \emph{on-line}. W tym przypadku wagi modyfikowane s¹ po
  		prezentacji próbki danych $s(k)=\{u(k), y(k) \}$. Wykorzystywana jest wtedy funkcja celu sieci neuronowej liczona dla
  		jednej lub kilku próbek (np. $N=1$ lub $N=5$ w (\ref{4.5.2})).
  		%
  		\par Druga metoda doboru wag sieci neuronowej nazywana jest \textbf{trenowaniem kumulacyjnym}, wsadowym
  		(ang. \emph{batch training}) lub trenowaniem w trybie \emph{off-line}. W tym przypadku, w jednym
  		cyklu tzw. epoce (ang. \emph{epoch}) prezentowane s¹ wszystkie próbki danych ze zbioru treningowego, a nastêpnie
  		obliczana jest funkcja celu sieci neuronowej dla wszystkich próbek.
  		%
  		\subsection{Zdolnoœæ uogólniania sieci neuronowej}
  		%
  		W trenowaniu kumulacyjnym sieci neuronowej, do trenowania wykorzystuje siê tzw. \emph{zbiór treningowy} próbek $s(k)$ (\ref{4.4.2}) wartoœci funkcji (\ref{4.4.1}) - ozn. $Z_{\mathrm{train}}$. Na jego podstawie mo¿na tak¿e okreœliæ jak dobrze uk³ad estymuje dane wykorzystane podczas trenowania sieci. Wartoœæ funkcji celu dla zbioru treningowego jest oznaczana $E_{\mathrm{train}}$ i nazywana \emph{b³êdem aproksymacji sieci neuronowej}.
  		%
  		\par Wytrenowana sieæ neuronowa powinna charakteryzowaæ siê dobr¹ zdolnoœci¹ generalizacji (uogólniania), czyli estymacji wartoœci funkcji $y(k)$ (\ref{4.4.1}), które nie by³y znane w procesie trenowania sieci, na podstawie sygna³ów wejœciowych $u(k)$. Do oceny uogólniania mo¿na wykorzystaæ \emph{zbiór testowy} $Z_{\mathrm{test}}$ próbek $s(k)$ o innych wartoœciach funkcji (\ref{4.4.1}) ni¿ zbiór treningowy. Wartoœæ funkcji celu dla zbioru testowego jest nazywana \emph{b³êdem uogólniania sieci neuronowej} lub \emph{b³êdem generalizacji sieci neuronowej} i oznaczana $E_{\mathrm{test}}$.
  		%
  		\par Na ogó³, gdy liczba próbek w zbiorze testowym i w zbiorze treningowym jest taka sama, b³¹d uogólniania $E_{\mathrm{test}}$ jest wiêkszy ni¿ b³¹d aproksymacji $E_{\mathrm{train}}$.
  		%
  		\par W³asnoœci aproksymacji i uogólniania sieci neuronowej œciœle zale¿¹ od jej budowy (liczby wag, neuronów i warstw) oraz liczby próbek
  		w zbiorze treningowym. Jednymi z warunków uzyskania dobrego uogólniania jest odpowiednia liczebnoœæ i ró¿norodnoœæ zbioru treningowego. Liczebnoœæ zbioru treningowego mo¿na okreœliæ wykorzystuj¹c miarê \emph{Vapnika - Chervonenkisa} $\mathrm{VCdim}$ \cite{vapnik:vc} dla danej struktury sieci neuronowej. Poniewa¿ jest to trudne zagadnienie, to w praktycznych rozwi¹zaniach stosuje siê oszacowanie wartoœci miary $\mathrm{VCdim}$. Granice miary $\mathrm{VCdim}$ zosta³y okreœlone dla ró¿nych struktur sieci neuronowych \cite{osowski:siecialg,osowski:sieci}. W praktyce podczas trenowania sieci neuronowej nale¿y przyj¹æ zbiór treningowy, w którym liczba próbek bêdzie przewy¿sza³a wartoœæ $\mathrm{VCdim}$.
  		%
  		\par Sieci neuronowe wykorzystywane w pracy s¹ sieciami jednokierunkowymi wielowarstwowymi. W ich przypadku
  		na podstawie znajomoœci granic miary $\mathrm{VCdim}$ \cite{osowski:sieci} przyjmuje siê oszacowanie wartoœci $\mathrm{VCdim}$ jako
  		liczbê wszystkich wag sieci ($n_{\mathrm{W}}$), natomiast minimaln¹ liczbê próbek zbioru treningowego $N_{\mathrm{train}}$ jako
  		%
  		\begin{equation}\label{4.6.3}
  		N_{\mathrm{train}} \approx 2\mathrm{VCdim} \approx 2n_{\mathrm{W}}
  		\end{equation}
  		%
  		Warunkiem uzyskania sieci dobrze uogólniaj¹cej, czyli dobrze aproksymuj¹cej dane testowe, jest wiêc przyjêcie liczby próbek w zbiorze treningowym przynajmniej dwukrotnie wiêkszej ni¿ liczba wszystkich wag sieci
  		%
  		\begin{equation}\label{4.6.4}
  		N_{\mathrm{train}} > 2n_{\mathrm{W}}
  		\end{equation}
  \section{Regulator stanu mechanizmu wielocz³oowego oparty o sieci neuronowe}
  \section{Logika rozmyta w sterowaniu mechanizmów wieloczlonowych}
  \section{Sterowanie ze wzmocnieniem mechanizmów wielocz³onowych}	
